{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbb718b4-2376-4582-86cd-be41c37de427",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Minimos Quadrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be4d8e0d-9f14-4e6d-861d-513c9268535a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8603\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def least_squares_classification(X, y, alpha):\n",
    "    # Adiciona uma coluna de 1s para representar o termo de viés\n",
    "    X = np.concatenate((np.ones((X.shape[0], 1)), X), axis=1)\n",
    "\n",
    "    # Calcula os coeficientes usando a fórmula dos mínimos quadrados com regularização de Ridge\n",
    "    theta = np.linalg.inv(X.T @ X + alpha * np.eye(X.shape[1])) @ X.T @ y\n",
    "\n",
    "    return theta\n",
    "\n",
    "def calculate_error(X, y, theta):\n",
    "    # Adiciona uma coluna de 1s para representar o termo de viés\n",
    "    X = np.concatenate((np.ones((X.shape[0], 1)), X), axis=1)\n",
    "\n",
    "    # Realiza as predições\n",
    "    predictions = X @ theta\n",
    "\n",
    "    # Converte as predições em rótulos\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Calcula o erro (taxa de erro)\n",
    "    error = np.mean(predicted_labels != y)\n",
    "\n",
    "    return error\n",
    "\n",
    "# Carrega o conjunto de dados MNIST\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Ajusta a forma dos dados\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Normaliza os dados dividindo por 255.0\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Converte os rótulos para uma representação one-hot\n",
    "num_classes = 10\n",
    "y_train_onehot = np.eye(num_classes)[y_train]\n",
    "\n",
    "# Define o valor de regularização (alpha)\n",
    "alpha = 0.01\n",
    "\n",
    "# Realiza a classificação usando mínimos quadrados com regularização de Ridge\n",
    "theta = least_squares_classification(X_train, y_train_onehot, alpha)\n",
    "\n",
    "# Adiciona uma coluna de 1s aos dados de teste\n",
    "X_test = np.concatenate((np.ones((X_test.shape[0], 1)), X_test), axis=1)\n",
    "\n",
    "# Realiza as predições\n",
    "predictions = X_test @ theta\n",
    "\n",
    "# Converte as predições em rótulos\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# # Calcula a acurácia\n",
    "# accuracy = np.mean(predicted_labels == y_test) * 100\n",
    "# print(\"Acurácia da classificação: {:.2f}%\".format(accuracy))\n",
    "\n",
    "# Calcular a precisão das previsões\n",
    "accuracy = accuracy_score(y_test, predicted_labels)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e71af66-3249-4d08-83e4-2d9461eac7fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Perceptron Logístico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2677d38-1d40-48f7-b3ea-2a2cfd6bb524",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d58910a3-6ab3-4a8d-ac22-e317f54e6fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia da classificação: 88.05%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Carrega o conjunto de dados MNIST\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Ajusta a forma dos dados\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Normaliza os dados dividindo por 255.0\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Cria uma instância do perceptron logístico\n",
    "model = Perceptron()\n",
    "\n",
    "# Treina o modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realiza as predições no conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcula a acurácia\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Acurácia da classificação: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce720c1-b0d8-4d7a-8ecd-c69b4bf3376f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## A mão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f14754d2-4bbd-4309-9a10-fd281ca699a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.datasets import mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6550bb67-5c48-423d-8766-4162dc1f837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticPerceptron:\n",
    "    def __init__(self, num_features, num_classes, learning_rate=0.01, num_epochs=100):\n",
    "        self.num_features = num_features\n",
    "        self.num_classes = num_classes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.weights = np.zeros((num_features + 1, num_classes))  # +1 for the bias term\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def predict(self, x):\n",
    "        activations = np.dot(np.insert(x, 0, 1), self.weights)\n",
    "        probabilities = self.sigmoid(activations)\n",
    "        return np.argmax(probabilities)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        X = np.insert(X, 0, 1, axis=1)  # Inserting bias term\n",
    "        y = np.eye(self.num_classes)[y]  # One-hot encoding\n",
    "        for _ in range(self.num_epochs):\n",
    "            for i in range(len(X)):\n",
    "                x = X[i]\n",
    "                target = y[i]\n",
    "                activations = np.dot(x, self.weights)\n",
    "                probabilities = self.sigmoid(activations)\n",
    "                error = target - probabilities\n",
    "                delta = self.learning_rate * np.outer(x, error)\n",
    "                self.weights += delta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f47de887-e728-479f-8d75-7cc8c13eacce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o conjunto de dados MNIST\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1077f8c-da7b-4923-a3be-950fef6e1396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajusta a forma dos dados\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c37ffb7-1572-431d-80c2-a5d74f9089c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar os dados\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68e4d936-67fa-4096-8b98-11af26455203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o objeto do perceptron logístico\n",
    "num_features = X_train.shape[1]\n",
    "num_classes = len(np.unique(y_train))\n",
    "perceptron = LogisticPerceptron(num_features=num_features, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16d57182-1cb0-4199-8523-9b1f906e0935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o perceptron\n",
    "perceptron.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dfcdb8d0-1f5f-4980-bad4-e95907d9a12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar previsões no conjunto de teste\n",
    "predictions = []\n",
    "for sample in X_test:\n",
    "    prediction = perceptron.predict(sample)\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b647280-98d3-4bfb-8f15-2e9bcdf6a5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9099\n"
     ]
    }
   ],
   "source": [
    "# Calcular a precisão das previsões\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed68398f-be04-41f0-abe1-decea7f82c5a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Minimos Quadrados + PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f61694d1-cf06-4006-8c2a-e439d25e72ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8611\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def least_squares_classification(X, y, alpha):\n",
    "    # Adiciona uma coluna de 1s para representar o termo de viés\n",
    "    X = np.concatenate((np.ones((X.shape[0], 1)), X), axis=1)\n",
    "\n",
    "    # Calcula os coeficientes usando a fórmula dos mínimos quadrados com regularização de Ridge\n",
    "    theta = np.linalg.inv(X.T @ X + alpha * np.eye(X.shape[1])) @ X.T @ y\n",
    "\n",
    "    return theta\n",
    "\n",
    "# Carregando o conjunto de dados MNIST\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Ajusta a forma dos dados\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Normalizar os dados\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# -------------------------- PCA -------------------------- #\n",
    "# --------------------------------------------------------- #\n",
    "# Calcular a matriz de covariância\n",
    "cov_matrix = np.cov(X_train.T)\n",
    "\n",
    "# Calcular os autovetores e autovalores\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# Ordenar os autovetores em ordem decrescente dos autovalores\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "sorted_eigenvalues = eigenvalues[sorted_indices]\n",
    "sorted_eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "# Escolher o número de componentes principais\n",
    "num_components = 100\n",
    "\n",
    "# Selecionar as componentes principais\n",
    "principal_components = sorted_eigenvectors[:, :num_components]\n",
    "\n",
    "# Projetar os dados nas componentes principais\n",
    "X_train_pca = np.dot(X_train, principal_components)\n",
    "\n",
    "# Projetar os dados nas componentes principais\n",
    "X_test_pca = np.dot(X_test, principal_components)\n",
    "\n",
    "# -------------------------- PCA -------------------------- #\n",
    "# --------------------------------------------------------- #\n",
    "\n",
    "# Converte os rótulos para uma representação one-hot\n",
    "num_classes = 10\n",
    "y_train_onehot = np.eye(num_classes)[y_train]\n",
    "\n",
    "# Define o valor de regularização (alpha)\n",
    "alpha = 0.01\n",
    "\n",
    "# Realiza a classificação usando mínimos quadrados com regularização de Ridge\n",
    "theta = least_squares_classification(X_train_pca, y_train_onehot, alpha)\n",
    "\n",
    "# Adiciona uma coluna de 1s aos dados de teste\n",
    "X_test = np.concatenate((np.ones((X_test_pca.shape[0], 1)), X_test_pca), axis=1)\n",
    "\n",
    "# Realiza as predições\n",
    "predictions = X_test @ theta\n",
    "\n",
    "# Converte as predições em rótulos\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# # Calcula a acurácia\n",
    "# accuracy = np.mean(predicted_labels == y_test) * 100\n",
    "# print(\"Acurácia da classificação: {:.2f}%\".format(accuracy))\n",
    "\n",
    "# Calcular a precisão das previsões\n",
    "accuracy = accuracy_score(y_test, predicted_labels)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00aab16-51f0-4b90-a52f-27244626dfb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448dc844-91eb-4abb-9c83-7beb088322d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac75ae3-1a38-4555-995f-7f6c9c779dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b226a62-be74-4724-9c5c-e03185f29fec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a539259e-17ea-4031-9f18-60a95f51fd51",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (10000,) and (784,155) not aligned: 10000 (dim 0) != 784 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m X_train_pca \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(X_train, principal_components)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Projetar os dados de teste nas componentes principais\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m X_test_pca \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprincipal_components\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# -------------------------- PCA -------------------------- #\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# --------------------------------------------------------- #\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Converte os rótulos para uma representação one-hot\u001b[39;00m\n\u001b[1;32m     53\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (10000,) and (784,155) not aligned: 10000 (dim 0) != 784 (dim 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def least_squares_classification(X, y, alpha):\n",
    "    # Adiciona uma coluna de 1s para representar o termo de viés\n",
    "    X = np.concatenate((np.ones((X.shape[0], 1)), X), axis=1)\n",
    "\n",
    "    # Calcula os coeficientes usando a fórmula dos mínimos quadrados com regularização de Ridge\n",
    "    theta = np.linalg.inv(X.T @ X + alpha * np.eye(X.shape[1])) @ X.T @ y\n",
    "\n",
    "    return theta\n",
    "\n",
    "# Carrega o conjunto de dados MNIST\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Ajusta a forma dos dados\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Normaliza os dados dividindo por 255.0\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# -------------------------- PCA -------------------------- #\n",
    "# --------------------------------------------------------- #\n",
    "# Calcular a matriz de covariância\n",
    "cov_matrix = np.cov(X_train.T)\n",
    "\n",
    "# Calcular os autovetores e autovalores\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# Ordenar os autovetores em ordem decrescente dos autovalores\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "sorted_eigenvalues = eigenvalues[sorted_indices]\n",
    "sorted_eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "# Escolher o número de componentes principais\n",
    "num_components = 155\n",
    "\n",
    "# Selecionar as componentes principais\n",
    "principal_components = sorted_eigenvectors[:, :num_components]\n",
    "\n",
    "# Projetar os dados de treino nas componentes principais\n",
    "X_train_pca = np.dot(X_train, principal_components)\n",
    "\n",
    "# Projetar os dados de teste nas componentes principais\n",
    "X_test_pca = np.dot(y_test, principal_components)\n",
    "# -------------------------- PCA -------------------------- #\n",
    "# --------------------------------------------------------- #\n",
    "\n",
    "# Converte os rótulos para uma representação one-hot\n",
    "num_classes = 10\n",
    "y_train_onehot = np.eye(num_classes)[y_train]\n",
    "\n",
    "# Define o valor de regularização (alpha)\n",
    "alpha = 0.01\n",
    "\n",
    "# Realiza a classificação usando mínimos quadrados com regularização de Ridge\n",
    "theta = least_squares_classification(X_train_pca, y_train_onehot, alpha)\n",
    "\n",
    "# Adiciona uma coluna de 1s aos dados de teste\n",
    "X_test = np.concatenate((np.ones((X_test.shape[0], 1)), X_test_pca), axis=1)\n",
    "\n",
    "# Realiza as predições\n",
    "predictions = X_test @ theta\n",
    "\n",
    "# Converte as predições em rótulos\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# # Calcula a acurácia\n",
    "# accuracy = np.mean(predicted_labels == y_test) * 100\n",
    "# print(\"Acurácia da classificação: {:.2f}%\".format(accuracy))\n",
    "\n",
    "# Calcular a precisão das previsões\n",
    "accuracy = accuracy_score(y_test, predicted_labels)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e16181-2f23-43b4-b3b2-cb66c4dc334a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Perceptron Logistico + PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e53df544-62e6-46ce-a08c-99e47885910d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9058\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "class LogisticPerceptron:\n",
    "    def __init__(self, num_features, num_classes, learning_rate=0.01, num_epochs=100):\n",
    "        self.num_features = num_features\n",
    "        self.num_classes = num_classes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.weights = np.zeros((num_features + 1, num_classes))  # +1 for the bias term\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def predict(self, x):\n",
    "        activations = np.dot(np.insert(x, 0, 1), self.weights)\n",
    "        probabilities = self.sigmoid(activations)\n",
    "        return np.argmax(probabilities)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        X = np.insert(X, 0, 1, axis=1)  # Inserting bias term\n",
    "        y = np.eye(self.num_classes)[y]  # One-hot encoding\n",
    "        for _ in range(self.num_epochs):\n",
    "            for i in range(len(X)):\n",
    "                x = X[i]\n",
    "                target = y[i]\n",
    "                activations = np.dot(x, self.weights)\n",
    "                probabilities = self.sigmoid(activations)\n",
    "                error = target - probabilities\n",
    "                delta = self.learning_rate * np.outer(x, error)\n",
    "                self.weights += delta\n",
    "\n",
    "\n",
    "# Carregando o conjunto de dados MNIST\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Ajusta a forma dos dados\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Normalizar os dados\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# -------------------------- PCA -------------------------- #\n",
    "# --------------------------------------------------------- #\n",
    "# Calcular a matriz de covariância\n",
    "cov_matrix = np.cov(X_train.T)\n",
    "\n",
    "# Calcular os autovetores e autovalores\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# Ordenar os autovetores em ordem decrescente dos autovalores\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "sorted_eigenvalues = eigenvalues[sorted_indices]\n",
    "sorted_eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "# Escolher o número de componentes principais\n",
    "num_components = 155\n",
    "\n",
    "# Selecionar as componentes principais\n",
    "principal_components = sorted_eigenvectors[:, :num_components]\n",
    "\n",
    "# Projetar os dados nas componentes principais\n",
    "X_train_pca = np.dot(X_train, principal_components)\n",
    "\n",
    "# Projetar os dados nas componentes principais\n",
    "X_test_pca = np.dot(X_test, principal_components)\n",
    "\n",
    "\n",
    "# -------------------------- PCA -------------------------- #\n",
    "# --------------------------------------------------------- #\n",
    "\n",
    "# Criar o objeto do perceptron logístico\n",
    "num_features = X_train_pca.shape[1]\n",
    "num_classes = len(np.unique(y_train))\n",
    "perceptron = LogisticPerceptron(num_features=num_features, num_classes=num_classes)\n",
    "\n",
    "# Treinar o perceptron\n",
    "perceptron.train(X_train_pca, y_train)\n",
    "\n",
    "# Realizar previsões no conjunto de teste\n",
    "predictions = []\n",
    "for sample in X_test_pca:\n",
    "    prediction = perceptron.predict(sample)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "# Calcular a precisão das previsões\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
